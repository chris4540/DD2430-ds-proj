{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    \n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def siam_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''    \n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_shape, num_classes):\n",
    "    image_input = Input(shape=input_shape)\n",
    "    model = resnet50.ResNet50(weights=\"imagenet\", include_top=True,\n",
    "                          input_tensor=image_input)\n",
    "    # 2048-D vector output\n",
    "    embd_output = model.get_layer('avg_pool').output\n",
    "    # can add more dense layers inbetween if required\n",
    "    classification_output = Dense(num_classes, activation='softmax', name='output_layer')(embd_output)\n",
    "    custom_resnet_model = Model(inputs=image_input, outputs= [embd_output, classification_output])\n",
    "    return custom_resnet_model\n",
    "\n",
    "def create_siamese_model(input_shape, num_classes):\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "    model = create_base_model(input_shape, num_classes)\n",
    "    embd_a, class_a = model(input_a)\n",
    "    embd_b, class_b = model(input_b)\n",
    "    # l2 norm for embeddings\n",
    "    norm_embd_a = K.l2_normalize(embd_a, axis=1)\n",
    "    norm_embd_b = K.l2_normalize(embd_b, axis=1)\n",
    "    # distance between embeddings\n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([norm_embd_a, norm_embd_b])\n",
    "    custom_siamese_model = Model([input_a, input_b], [distance, class_a, class_b])\n",
    "    return custom_siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = create_siamese_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lambda_1', 'model_2', 'model_2_1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names = s_model.output_names\n",
    "losses = {\n",
    "    output_names[0]: contrastive_loss,\n",
    "    output_names[1]: \"categorical_crossentropy\",\n",
    "    output_names[2]: \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {output_names[0]:1.0,output_names[1]: 1.0, output_names[2]: 1.0}\n",
    "\n",
    "#top k accuracy would be better i guess\n",
    "all_metrics = {\n",
    "    output_names[0]: siam_accuracy,\n",
    "    output_names[1]: \"accuracy\",\n",
    "    output_names[2]: \"accuracy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "s_model.compile(loss=losses, loss_weights=lossWeights, optimizer=rms, metrics=all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
