{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('DeepFashion1/deepfashion1_categoryData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>category_label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>val</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            images  category_label dataset  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg               3   train   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg               3   train   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               3     val   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg               3   train   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg               3    test   \n",
       "\n",
       "  category  label  \n",
       "0   Blouse      2  \n",
       "1   Blouse      2  \n",
       "2   Blouse      2  \n",
       "3   Blouse      2  \n",
       "4   Blouse      2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFashionDataset():\n",
    "    \n",
    "    def __init__(self, filepath, dataset_type, transforms=None):\n",
    "        \n",
    "        assert(dataset_type in ['train', 'val', 'test'])\n",
    "        \n",
    "        self.dataset_type = dataset_type\n",
    "        \n",
    "        if self.dataset_type == 'train':\n",
    "            self.train = True\n",
    "        else:\n",
    "            self.train = False\n",
    "            \n",
    "        self.alldata = pd.read_csv(filepath)\n",
    "        self.data = self.alldata[self.alldata.dataset == self.dataset_type][['images', 'label']]\n",
    "        \n",
    "        self.transform = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDeepFashion(Dataset):\n",
    "    \"\"\"\n",
    "    Train: For each sample creates randomly a positive or a negative pair\n",
    "    Test: Creates fixed pairs for testing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deepfashion_dataset, dataset_folder_name):\n",
    "        \n",
    "        self.datafolder = dataset_folder_name\n",
    "        self.deepfashion_dataset = deepfashion_dataset\n",
    "\n",
    "        self.train = self.deepfashion_dataset.train\n",
    "        self.transform = self.deepfashion_dataset.transform\n",
    "\n",
    "        if self.train:\n",
    "            self.train_labels = self.deepfashion_dataset.data.label.values\n",
    "            self.train_data = self.deepfashion_dataset.data.images.values\n",
    "            self.labels_set = set(self.train_labels)\n",
    "            self.label_to_indices = {label: np.where(self.train_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "        else:\n",
    "            # generate fixed pairs for testing\n",
    "            self.test_labels = self.deepfashion_dataset.data.label.values\n",
    "            self.test_data = self.deepfashion_dataset.data.images.values\n",
    "            self.labels_set = set(self.test_labels)\n",
    "            self.label_to_indices = {label: np.where(self.test_labels == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "\n",
    "            random_state = np.random.RandomState(29)\n",
    "\n",
    "            positive_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[self.test_labels[i].item()]),\n",
    "                               1]\n",
    "                              for i in range(0, len(self.test_data), 2)]\n",
    "\n",
    "            negative_pairs = [[i,\n",
    "                               random_state.choice(self.label_to_indices[\n",
    "                                                       np.random.choice(\n",
    "                                                           list(self.labels_set - set([self.test_labels[i].item()]))\n",
    "                                                       )\n",
    "                                                   ]),\n",
    "                               0]\n",
    "                              for i in range(1, len(self.test_data), 2)]\n",
    "            self.test_pairs = positive_pairs + negative_pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            target = np.random.randint(0, 2)\n",
    "            img1, label1 = self.train_data[index], self.train_labels[index].item()\n",
    "            if target == 1:\n",
    "                siamese_index = index\n",
    "                while siamese_index == index:\n",
    "                    siamese_index = np.random.choice(self.label_to_indices[label1])\n",
    "            else:\n",
    "                siamese_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "                siamese_index = np.random.choice(self.label_to_indices[siamese_label])\n",
    "            img2 = self.train_data[siamese_index]\n",
    "        else:\n",
    "            img1 = self.test_data[self.test_pairs[index][0]]\n",
    "            img2 = self.test_data[self.test_pairs[index][1]]\n",
    "            target = self.test_pairs[index][2]\n",
    "\n",
    "        img1 = Image.open(self.datafolder+'/'+img1)\n",
    "        img2 = Image.open(self.datafolder+'/'+img2)\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return (img1, img2), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.deepfashion_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                 #transforms.Resize((224,224)),\n",
    "                                 transforms.ToTensor()\n",
    "                              ])\n",
    "\n",
    "train_data = DeepFashionDataset('DeepFashion1/deepfashion1_categoryData.csv', 'train', train_transform)\n",
    "test_data = DeepFashionDataset('DeepFashion1/deepfashion1_categoryData.csv', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209222, 2), (40000, 2))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape, test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SiameseDeepFashion(train_data, 'DeepFashion1')\n",
    "test_loader = SiameseDeepFashion(test_data, 'DeepFashion1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[0.9412, 0.9412, 0.9412,  ..., 0.9137, 0.9098, 0.9098],\n",
       "           [0.9412, 0.9412, 0.9412,  ..., 0.9137, 0.9098, 0.9098],\n",
       "           [0.9412, 0.9412, 0.9412,  ..., 0.9137, 0.9137, 0.9098],\n",
       "           ...,\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9294, 0.9294],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9333, 0.9294],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9333, 0.9333]],\n",
       "  \n",
       "          [[0.9412, 0.9412, 0.9412,  ..., 0.9176, 0.9137, 0.9137],\n",
       "           [0.9412, 0.9412, 0.9412,  ..., 0.9176, 0.9137, 0.9137],\n",
       "           [0.9412, 0.9412, 0.9412,  ..., 0.9176, 0.9176, 0.9137],\n",
       "           ...,\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9294, 0.9294],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9333, 0.9294],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9333, 0.9333, 0.9333]],\n",
       "  \n",
       "          [[0.9490, 0.9490, 0.9490,  ..., 0.9255, 0.9216, 0.9216],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9255, 0.9216, 0.9216],\n",
       "           [0.9490, 0.9490, 0.9490,  ..., 0.9255, 0.9255, 0.9216],\n",
       "           ...,\n",
       "           [0.9569, 0.9569, 0.9569,  ..., 0.9412, 0.9373, 0.9373],\n",
       "           [0.9569, 0.9569, 0.9569,  ..., 0.9412, 0.9412, 0.9373],\n",
       "           [0.9569, 0.9569, 0.9569,  ..., 0.9412, 0.9412, 0.9412]]]),\n",
       "  tensor([[[0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
       "           [0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
       "           [0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
       "           ...,\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333],\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333],\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333]],\n",
       "  \n",
       "          [[0.9608, 0.9608, 0.9608,  ..., 0.9608, 0.9608, 0.9608],\n",
       "           [0.9608, 0.9608, 0.9608,  ..., 0.9608, 0.9608, 0.9608],\n",
       "           [0.9608, 0.9608, 0.9608,  ..., 0.9608, 0.9608, 0.9608],\n",
       "           ...,\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333],\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333],\n",
       "           [0.9098, 0.9137, 0.9137,  ..., 0.9373, 0.9333, 0.9333]],\n",
       "  \n",
       "          [[0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
       "           [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
       "           [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
       "           ...,\n",
       "           [0.9176, 0.9216, 0.9216,  ..., 0.9451, 0.9412, 0.9412],\n",
       "           [0.9176, 0.9216, 0.9216,  ..., 0.9451, 0.9412, 0.9412],\n",
       "           [0.9176, 0.9216, 0.9216,  ..., 0.9451, 0.9412, 0.9412]]])),\n",
       " 1)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209222"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
