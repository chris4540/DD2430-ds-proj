{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DeepFashion1/deepfashion1_categoryData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>category_label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>val</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            images  category_label dataset  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg               3   train   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg               3   train   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               3     val   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg               3   train   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg               3    test   \n",
       "\n",
       "  category  label  \n",
       "0   Blouse      2  \n",
       "1   Blouse      2  \n",
       "2   Blouse      2  \n",
       "3   Blouse      2  \n",
       "4   Blouse      2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress          72158\n",
       "Tee            36887\n",
       "Blouse         24557\n",
       "Shorts         19666\n",
       "Tank           15429\n",
       "Skirt          14773\n",
       "Cardigan       13311\n",
       "Sweater        13123\n",
       "Jacket         10467\n",
       "Top            10078\n",
       "Blazer          7495\n",
       "Romper          7408\n",
       "Jeans           7076\n",
       "Jumpsuit        6153\n",
       "Leggings        5013\n",
       "Joggers         4416\n",
       "Hoodie          4048\n",
       "Sweatpants      3048\n",
       "Kimono          2294\n",
       "Coat            2120\n",
       "Cutoffs         1669\n",
       "Sweatshorts     1106\n",
       "Poncho           791\n",
       "Jersey           748\n",
       "Henley           716\n",
       "Parka            676\n",
       "Jeggings         594\n",
       "Chinos           527\n",
       "Culottes         486\n",
       "Trunks           386\n",
       "Button-Down      330\n",
       "Flannel          324\n",
       "Bomber           309\n",
       "Anorak           160\n",
       "Robe             150\n",
       "Turtleneck       146\n",
       "Kaftan           126\n",
       "Peacoat           97\n",
       "Capris            77\n",
       "Onesie            70\n",
       "Caftan            54\n",
       "Gauchos           49\n",
       "Jodhpurs          45\n",
       "Sarong            32\n",
       "Coverup           17\n",
       "Halter            17\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(df, col_name, min_treshold, random_seed=42):\n",
    "    # remove all data belonging to all classes with total count less than minimum treshold\n",
    "    resampled_data = df.groupby(col_name).filter(lambda x : len(x)>min_treshold)\n",
    "    # minimum count of any class\n",
    "    min_count = resampled_data[col_name].value_counts().min()\n",
    "    return (resampled_data.groupby(col_name)\n",
    "            .apply(lambda x: x.sample(min_count, random_state=random_seed))\n",
    "            .reset_index(drop=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = resample(data, 'category', 5000, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skirt       5013\n",
       "Jumpsuit    5013\n",
       "Tee         5013\n",
       "Tank        5013\n",
       "Cardigan    5013\n",
       "Jeans       5013\n",
       "Jacket      5013\n",
       "Dress       5013\n",
       "Leggings    5013\n",
       "Blouse      5013\n",
       "Shorts      5013\n",
       "Romper      5013\n",
       "Sweater     5013\n",
       "Blazer      5013\n",
       "Top         5013\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNOY and Top-K\n",
    "\n",
    "ANNOY: https://github.com/spotify/annoy\n",
    "\n",
    "Since we are not sure how the embeddings would be passed in the pipeline. I am just assuming like the following dataframe. Iportant point is we need image_embedding and corresponding label.\n",
    "\n",
    "(check annoy github link above)\n",
    "\n",
    "We can get the similar images from vector (as used below) or we can get it by index using \"t.get_nns_by_item\" \n",
    "\n",
    "We can also get the distance for each of the top k image from the input image as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pickle.load(open('subdata.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>category_label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>embd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.8212891, 1.0950764, 0.19870186, 0.03826549,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.22787644, 1.6668769, 0.32685006, 0.0, 0.073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>val</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.27398872, 1.0369267, 0.08694938, 0.07015417...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.014149437, 0.92608607, 0.2060591, 0.8770616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.8263322, 1.5453025, 0.20867401, 0.16627665,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            images  category_label dataset  \\\n",
       "0  img/Sheer_Pleated-Front_Blouse/img_00000001.jpg               3   train   \n",
       "1  img/Sheer_Pleated-Front_Blouse/img_00000002.jpg               3   train   \n",
       "2  img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               3     val   \n",
       "3  img/Sheer_Pleated-Front_Blouse/img_00000004.jpg               3   train   \n",
       "4  img/Sheer_Pleated-Front_Blouse/img_00000005.jpg               3    test   \n",
       "\n",
       "  category  label                                               embd  \n",
       "0   Blouse      2  [0.8212891, 1.0950764, 0.19870186, 0.03826549,...  \n",
       "1   Blouse      2  [0.22787644, 1.6668769, 0.32685006, 0.0, 0.073...  \n",
       "2   Blouse      2  [0.27398872, 1.0369267, 0.08694938, 0.07015417...  \n",
       "3   Blouse      2  [0.014149437, 0.92608607, 0.2060591, 0.8770616...  \n",
       "4   Blouse      2  [0.8263322, 1.5453025, 0.20867401, 0.16627665,...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding length\n",
    "f = len(embeddings_df['embd'][0])\n",
    "# create annoy index\n",
    "# metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"\n",
    "t = AnnoyIndex(f, metric='euclidean')\n",
    "# tradeoff between accuracy and speed\n",
    "n_trees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the index\n",
    "for i, vector in enumerate(embeddings_df['embd']):\n",
    "    t.add_item(i, vector)\n",
    "# build a forest of trees\n",
    "_  = t.build(n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_K(img_embd, image_label, embd_map=embeddings_df, K=5):\n",
    "    # assuming test image is not already indexed (in that case have to use K+1) \n",
    "    similar_img_ids = t.get_nns_by_vector(img_embd, K)\n",
    "    top_k = embd_map.iloc[similar_img_ids][\"label\"].tolist().count(image_label)\n",
    "    accuracy = top_k/K\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K_similar_images(img_embd, image_label, embd_map=embeddings_df, K=5):\n",
    "    # assuming test image is not already indexed (in that case have to use K+1)  \n",
    "    similar_img_ids = t.get_nns_by_vector(img_embd, K)\n",
    "    top_k_images = embd_map.iloc[similar_img_ids]\n",
    "    return top_k_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
